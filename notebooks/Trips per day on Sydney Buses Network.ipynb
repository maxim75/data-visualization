{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19b486b6-ceed-4fa8-a755-8d78a253943e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import contextily as ctx\n",
    "import pyproj\n",
    "from shapely.geometry import Point, LineString\n",
    "from zipfile import ZipFile, Path\n",
    "import datetime\n",
    "from matplotlib.colors import TwoSlopeNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fa97a22-ca41-4479-9d69-befaa3121c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_date_str = \"2021-09-27\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775689cb-9153-4976-b944-570f21e1bedf",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Transport NSW GTFS data is available for download from: https://opendata.transport.nsw.gov.au/node/4035/download\n",
    "\n",
    "Requires new user registration\n",
    "\n",
    "Code assumes file is located at following path:\n",
    "`data/local_only/full_greater_sydney_gtfs_parent_TSN.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44a6d0a8-95b5-4ad2-98a7-b69da2b80a3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named 'shapes.txt' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_286/919114890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#with ZipFile(\"data/local_only/full_greater_sydney_gtfs_parent_TSN.zip\") as myzip:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/local_only/germany_gtfs.zip\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     shapes_df = pd.read_csv(myzip.open(\"shapes.txt\"), dtype={\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;34m'shape_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m'shape_pt_lat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1500\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0;31m# Get info object for name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m             \u001b[0mzinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/zipfile.py\u001b[0m in \u001b[0;36mgetinfo\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNameToInfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m   1430\u001b[0m                 'There is no item named %r in the archive' % name)\n\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"There is no item named 'shapes.txt' in the archive\""
     ]
    }
   ],
   "source": [
    "#with ZipFile(\"data/local_only/full_greater_sydney_gtfs_parent_TSN.zip\") as myzip:\n",
    "with ZipFile(\"data/local_only/germany_gtfs.zip\") as myzip:\n",
    "    shapes_df = pd.read_csv(myzip.open(\"shapes.txt\"), dtype={\n",
    "        'shape_id': 'str', \n",
    "        'shape_pt_lat': 'float', \n",
    "        'shape_pt_lon': 'float',  \n",
    "        'shape_pt_sequence': 'Int64', \n",
    "        'shape_dist_traveled': 'float',\n",
    "    })\n",
    "    shapes_gdf = gpd.GeoDataFrame(shapes_df, \n",
    "        geometry=gpd.points_from_xy(shapes_df.shape_pt_lon, shapes_df.shape_pt_lat)).set_crs(epsg=4326)\n",
    "    \n",
    "    stops_df = pd.read_csv(myzip.open(\"stops.txt\"), dtype={ 'stop_id': 'str', \n",
    "        'stop_code': 'str',\n",
    "        'stop_name': 'str',\n",
    "        'stop_lat': 'float',\n",
    "        'stop_lon': 'float',\n",
    "        'location_type': 'Int64',\n",
    "        'parent_station': 'str',\n",
    "        'wheelchair_boarding': 'str', \n",
    "        'platform_code': 'str',})\n",
    "    stops_gdf = gpd.GeoDataFrame(stops_df, \n",
    "        geometry=gpd.points_from_xy(stops_df.stop_lon, stops_df.stop_lat)).set_crs(epsg=4326)\n",
    "    \n",
    "    routes_df = pd.read_csv(myzip.open(\"routes.txt\"), dtype={\n",
    "        'route_id': 'str',  \n",
    "        'agency_id': 'str',  \n",
    "        'route_short_name': 'str',  \n",
    "        'route_long_name': 'str', \n",
    "        'route_desc': 'str', \n",
    "        'route_type': 'Int64',\n",
    "        'route_color': 'str',  \n",
    "        'route_text_color': 'str', \n",
    "        'exact_times': 'bool'\n",
    "    })\n",
    "    \n",
    "    trips_df = pd.read_csv(myzip.open(\"trips.txt\"), dtype={\n",
    "        'route_id': 'str', \n",
    "        'service_id': 'str',  \n",
    "        'trip_id': 'str',\n",
    "        'shape_id': 'str', \n",
    "        'trip_headsign': 'str', \n",
    "        'direction_id': 'str',  \n",
    "        'block_id': 'str', \n",
    "        'wheelchair_accessible': 'str', \n",
    "        'route_direction': 'str', \n",
    "        'trip_note': 'str', \n",
    "        'bikes_allowed': 'str'\n",
    "    })\n",
    "    \n",
    "    stop_times_df = pd.read_csv(myzip.open(\"stop_times.txt\"), dtype={\n",
    "        'trip_id': 'str',\n",
    "        'arrival_time': 'str',\n",
    "        'stop_id': 'str', \n",
    "        'departure_time': 'str', \n",
    "        'stop_id': 'str',\n",
    "        'stop_sequence': 'Int64',\n",
    "        'stop_headsign': 'str',\n",
    "        'pickup_type': 'Int64',\n",
    "        'drop_off_type': 'Int64',\n",
    "        'shape_dist_traveled': 'float',\n",
    "        'timepoint': 'bool',\n",
    "        'stop_note': 'str',\n",
    "    }).astype({})\n",
    "    \n",
    "    agency_df = pd.read_csv(myzip.open(\"agency.txt\"), dtype={\n",
    "        'agency_id': 'str', \n",
    "        'agency_name': 'str', \n",
    "        'agency_url': 'str',  \n",
    "        'agency_timezone': 'str',\n",
    "        'agency_lang': 'str', \n",
    "        'agency_phone': 'str',\n",
    "    })\n",
    "    \n",
    "    calendar_df = pd.read_csv(myzip.open(\"calendar.txt\"), dtype={\n",
    "        'service_id': 'str',  \n",
    "        'monday': 'bool',  \n",
    "        'tuesday': 'bool',  \n",
    "        'wednesday': 'bool',  \n",
    "        'thursday': 'bool',  \n",
    "        'friday': 'bool', \n",
    "        'saturday': 'bool',  \n",
    "        'sunday': 'bool',  \n",
    "        'start_date': 'str', \n",
    "        'end_date': 'str',\n",
    "    })\n",
    "    \n",
    "    calendar_dates_df = pd.read_csv(myzip.open(\"calendar_dates.txt\"), dtype={\n",
    "        'service_id': 'str',  \n",
    "        'date': 'str',\n",
    "        'exception_type': 'Int64',\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881e666-cc70-449e-bec7-3a210fbb2dcd",
   "metadata": {},
   "source": [
    "# Find services running on that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03168a6-3f2b-4ac9-9032-2c578661d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.datetime.strptime(show_date_str, \"%Y-%m-%d\")\n",
    "date_string = date.strftime(\"%Y%m%d\")\n",
    "day_of_week_name = date.strftime('%A').lower()\n",
    "\n",
    "services_for_day_1 = calendar_df[(calendar_df[day_of_week_name]) & (date_string >= calendar_df.start_date) & (date_string <= calendar_df.end_date)].service_id.to_numpy()\n",
    "print(f\"scheduled for day based on calendar: {len(services_for_day_1)}\")\n",
    "\n",
    "# exception_type\n",
    "# 1 - Service has been added for the specified date.\n",
    "# 2 - Service has been removed for the specified date.\n",
    "services_added_for_day = calendar_dates_df[(calendar_dates_df.date == date_string) & (calendar_dates_df.exception_type == 1)].service_id.to_numpy()\n",
    "services_removed_for_day = calendar_dates_df[(calendar_dates_df.date == date_string) & (calendar_dates_df.exception_type == 2)].service_id.to_numpy()\n",
    "print(f\"services added using calendar_dates: {len(services_added_for_day)}\")\n",
    "print(f\"services removed using calendar_dates: {len(services_removed_for_day)}\")\n",
    "\n",
    "services_for_day_2 = np.concatenate([services_for_day_1, services_added_for_day])\n",
    "services_for_day = np.setdiff1d(services_for_day_2, services_removed_for_day)\n",
    "\n",
    "print(f\"final services for day: {len(services_for_day)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503fab68-f95c-47f6-b989-cc1285b774dc",
   "metadata": {},
   "source": [
    "# Get each route segment with start and end coordinates and sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47625a8-02da-49a6-8c03-cbaadbf3c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = shapes_df[[\"shape_pt_lat\", \"shape_pt_lon\", \"shape_pt_sequence\"]]\n",
    "coords_roll_1 = np.roll(coords, 1, axis=0)\n",
    "\n",
    "segments = pd.DataFrame(np.concatenate([coords_roll_1, coords], axis=1), columns=[\"start_lat\", \"start_lng\", \"start_seq\", \n",
    "                                                                       \"end_lat\", \"end_lng\", \"end_seq\"])\n",
    "segments_df = shapes_df[[\"shape_id\"]].join(segments)\n",
    "segments_df = segments_df[segments_df.end_seq != 1]\n",
    "segments_df = segments_df.drop(columns=['end_seq']).rename(columns={ \"start_seq\": \"seq\" })\n",
    "segments_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c120c7-6466-4803-911e-cd6cb91579c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get number of trips for each shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff2927-154b-4c00-abf4-b39897e2c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_trips = trips_df[trips_df.service_id.isin(services_for_day)]\n",
    "sydney_bus_route_ids = routes_df[routes_df.route_desc == \"Sydney Buses Network\"].route_id.unique()\n",
    "shape_day_trips = day_trips[day_trips.route_id.isin(sydney_bus_route_ids)].groupby(by=\"shape_id\").size().to_frame(\"day_trips\")\n",
    "shape_day_trips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8630d3-c26f-49c5-850d-24f34ca7d0d6",
   "metadata": {},
   "source": [
    "# Merge segments with day trip counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88234e-1244-4789-b1d7-285028ed50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_segments_day_trips = pd.merge(segments_df, shape_day_trips, left_on=\"shape_id\", right_index=True)\n",
    "\n",
    "# how many trip occurs in each segment per day\n",
    "shape_segments_day_trips = pd.merge(segments_df, shape_day_trips, left_on=\"shape_id\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1232f9-c157-46c1-b3d8-665d0937bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_day_trips = shape_segments_day_trips.groupby(by=[\n",
    "    \"start_lat\", \"start_lng\", \"end_lat\", \"end_lng\"]).sum(\"day_trips\").reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15bd8a7-76ed-4c31-903b-4c4b551e0c60",
   "metadata": {},
   "source": [
    "# Create LineString geometry for segment and create GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d875f75-00b5-46aa-a1f8-2cf6d6da32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "def get_line_string(row):\n",
    "    start = Point(row.start_lng, row.start_lat)\n",
    "    end = Point(row.end_lng, row.end_lat)\n",
    "    line = LineString([start, end])\n",
    "    row[\"geometry\"] = line\n",
    "    return row\n",
    "\n",
    "segment_day_trips_gpd = gpd.GeoDataFrame(segment_day_trips.apply(get_line_string, axis=1)).set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fd5b7-66eb-46d3-92ca-3f8868f74688",
   "metadata": {},
   "source": [
    "# Plot each segment with color showing number of trips per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad42b8-b2db-4e8c-9ea1-c62dc21f59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = segment_day_trips_gpd[\"day_trips\"].min()\n",
    "vmax = segment_day_trips_gpd[\"day_trips\"].quantile(.95)\n",
    "vcenter = segment_day_trips_gpd[\"day_trips\"].mean()\n",
    "norm = TwoSlopeNorm(vmin=vmin, vcenter=vcenter, vmax=vmax)\n",
    "\n",
    "fig = plt.figure(figsize=(30,21))\n",
    "ax = plt.axes()\n",
    "ax.set(facecolor = \"black\")\n",
    "\n",
    "def limit_to_bounding_box(gdf, bounding_box):\n",
    "    return gdf.cx[bounding_box[\"west\"]:bounding_box[\"east\"],bounding_box[\"south\"]:bounding_box[\"north\"]]\n",
    "\n",
    "# Greater Sydney bounding box\n",
    "sydney_bb = {\n",
    "    \"north\": -33.62,\n",
    "    \"south\": -34.086,\n",
    "    \"west\": 150.6,\n",
    "    \"east\": 151.38,\n",
    "}\n",
    "\n",
    "sydney_segment_day_trips_gpd = limit_to_bounding_box(segment_day_trips_gpd, sydney_bb)\n",
    "\n",
    "sydney_segment_day_trips_gpd.plot(ax=ax, cmap=\"plasma\", column='day_trips', legend=True, norm=norm)\n",
    "\n",
    "ax.set_title(f\"Number of trips per day on Sydney Buses Network on {date:%d %B %Y}\", fontsize=30)\n",
    "\n",
    "plt.savefig(\"Sydney Buses Network.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649977e-0c9d-4152-928e-5ba6b2524cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "sydney_segment_day_trips_gpd[[\"day_trips\", \"geometry\"]].to_csv(\"data/sydney_bus_network_segments.csv.zip\", compression=\"zip\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
